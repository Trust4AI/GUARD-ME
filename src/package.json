{
  "name": "guard-me",
  "version": "1.0.0",
  "description": "GUARD-ME evaluates bias in AI-enabled search engines by evaluating the responses to the source and follow-up test cases. It utilizes Large Language Models (LLMs) to detect any bias and ensure that these systems adhere to ethical standards.",
  "main": "index.js",
  "scripts": {
    "build": "npx tsc",
    "start": "node dist/index.js",
    "dev": "concurrently \"npx tsc --watch\" \"cross-env DEBUG_MODE=true nodemon -q dist/index.js\"",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/Trust4AI/GUARD-ME.git"
  },
  "author": "Trust4AI",
  "license": "GPL-3.0",
  "bugs": {
    "url": "https://github.com/Trust4AI/GUARD-ME/issues"
  },
  "homepage": "https://github.com/Trust4AI/GUARD-ME#readme",
  "dependencies": {
    "@google/generative-ai": "0.14.1",
    "ajv": "8.14.0",
    "awilix": "10.0.1",
    "cors": "2.8.5",
    "dotenv": "16.4.4",
    "express": "4.19.2",
    "express-validator": "7.0.1",
    "openai": "4.28.0",
    "swagger-jsdoc": "6.2.8",
    "swagger-ui-express": "5.0.0"
  },
  "devDependencies": {
    "@types/cors": "2.8.17",
    "@types/express": "4.17.21",
    "@types/node": "20.11.19",
    "@types/swagger-jsdoc": "6.0.4",
    "@types/swagger-ui-express": "4.1.6",
    "concurrently": "8.2.2",
    "cross-env": "7.0.3",
    "nodemon": "3.0.3",
    "typescript": "5.3.3"
  }
}